{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzjiujiu/AML-Affordance-detection/blob/main/3DHighlighter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boot the colab"
      ],
      "metadata": {
        "id": "AWggbpuWCUle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPi-fh_tCBh3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvMupHUD0G-"
      },
      "outputs": [],
      "source": [
        "!mkdir ./data_extension\n",
        "!cp -r ./drive/MyDrive/data/full_shape_val_data.pkl ./data_extension/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wzjiujiu/AML-Affordance-detection.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TZlPTvm91dbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required packages"
      ],
      "metadata": {
        "id": "x1u2hyhHCRyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PigOw_d2E15i",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install ftfy regex tqdm\n",
        "!pip install open3d\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runing on the voxel version"
      ],
      "metadata": {
        "id": "ru0qwzROlrWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 1 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NllsZ4jGBJ9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 2 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IwcgY2kblx9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 3 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "id": "heufzsBZl0N_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 0 --n_iter 100 --voxel True"
      ],
      "metadata": {
        "id": "HpDwR7LB4i0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r voxel_results.zip ./voxel_results\n",
        "files.download(\"./voxel_results.zip\")"
      ],
      "metadata": {
        "id": "0monxCxzDY4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2DpY1QfUvI4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running on the approximate mesh"
      ],
      "metadata": {
        "id": "B5o2NI-yvL7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 0 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "id": "EkMw_mJ5vVnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 19 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "id": "CzYL3kkAfyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 2 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "id": "rKGM3jXVfyny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --seed 5 --n_iter 100 --appro_mesh True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ODmj6xnHf0il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is the demo of running the project"
      ],
      "metadata": {
        "id": "CY9YBS9uASnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lOg6_DwGbb9"
      },
      "outputs": [],
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle --seed 0 --classes hat --object candle --n_iter 100 --frontview_center 3.14 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid serach"
      ],
      "metadata": {
        "id": "4AD8MfjiAfUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Se1Duec6odvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base00 --prompt '11111QA dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 0"
      ],
      "metadata": {
        "id": "sICyK89GlI6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##dog"
      ],
      "metadata": {
        "id": "zDSJ-OSRHA5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base00 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base01 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base02 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base03 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base04 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base05 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base06 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base07 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base08 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base09 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base10 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base11 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base12 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base13 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base14 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base15 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base16 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base17 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base18 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base19 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base20 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base21 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base22 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base23 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base24 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base25 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base26 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base27 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base28 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base29 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base30 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base31 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base32 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base33 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base34 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base35 --prompt 'A dog boots to protect its paws' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 4"
      ],
      "metadata": {
        "id": "dNFg-4VbKbkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##candle"
      ],
      "metadata": {
        "id": "wDOHEfEfN43R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base0 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base1 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base2 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base3 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 3 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base4 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base5 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base6 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base7 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base8 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base9 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base10 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base11 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base12 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base13 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base14 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base15 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base16 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base17 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base18 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base19 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base20 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base21 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base22 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base23 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base24 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base25 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base26 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base27 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base28 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base29 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base30 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base31 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base32 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base33 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base34 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base35 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 4\n"
      ],
      "metadata": {
        "id": "wCtvpSHWNu9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##horse"
      ],
      "metadata": {
        "id": "gUPQnbWPN8Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base5 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base6 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base7 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base8 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base9 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base10 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base11 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 3 --n_views 10 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base12 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base13 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base14 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base15 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 3 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base16 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base17 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base18 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base19 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base20 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base21 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base22 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base23 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 6 --n_views 10 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base24 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base25 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base26 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base27 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 3 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base28 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base29 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base30 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base31 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 6 --n_augs 4\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base32 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 0\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base33 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base34 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base35 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.001 --depth 10 --n_views 10 --n_augs 4\n"
      ],
      "metadata": {
        "id": "i-1qSQf1N_AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Automated search the hyperparameter"
      ],
      "metadata": {
        "id": "AKCuDwedAj0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse --seed 0 --classes horse --object horse --n_iter 1000 --frontview_center 3.14 0"
      ],
      "metadata": {
        "id": "rxcZMx4ehUKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save the result"
      ],
      "metadata": {
        "id": "PQCvg_haQQ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip ./results"
      ],
      "metadata": {
        "id": "wDgUQ55GSR-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/drive/MyDrive/3DHighlighter/results/"
      ],
      "metadata": {
        "id": "gqHycttNS8OO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Pus0peAOEphU"
      ],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}