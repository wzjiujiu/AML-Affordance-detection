{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzjiujiu/AML-Affordance-detection/blob/main/3DHighlighter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AML_PROJECT**:\n",
        "Author:Liu Yonghu, He Haochen, kang chenghua\n"
      ],
      "metadata": {
        "id": "Nd_XXIEinB75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boot the colab"
      ],
      "metadata": {
        "id": "AWggbpuWCUle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly perpared data we needed which stroed in google dirve, and results were saved there.  "
      ],
      "metadata": {
        "id": "bYXGJjLSlOoU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPi-fh_tCBh3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy dataset into colab"
      ],
      "metadata": {
        "id": "IVrL7j9VnWOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvMupHUD0G-"
      },
      "outputs": [],
      "source": [
        "!mkdir ./data_extension\n",
        "!cp -r ./drive/MyDrive/data/full_shape_val_data.pkl ./data_extension/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy code from github"
      ],
      "metadata": {
        "id": "C-voubSLna8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wzjiujiu/AML-Affordance-detection.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TZlPTvm91dbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages"
      ],
      "metadata": {
        "id": "x1u2hyhHCRyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PigOw_d2E15i",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install ftfy regex tqdm\n",
        "!pip install open3d\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lOg6_DwGbb9"
      },
      "outputs": [],
      "source": [
        "#This is the demo of running the project\n",
        "!python ./AML-Affordance-detection/main.py --obj_path /AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle --seed 0 --classes hat --object candle --n_iter 100 --frontview_center 3.14 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run projects on third-party servers(Optional)"
      ],
      "metadata": {
        "id": "j_WIhcxQ2GBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Following code is using on Third-party servers:\n",
        "#Some third-party servers have kaolin installed but the version does not match the torch version.\n",
        "#Use following code to reinstall kaolin and torch.\n",
        "#No need to run all previous code if you use third-part servers, include \"Boot the colab\" and \"Install required packages\".\n",
        "#if you use google colab official servers please ignore this part.\n",
        "!git clone https://github.com/wzjiujiu/AML-Affordance-detection.git\n",
        "!pip uninstall --y kaolin\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip cache purge\n",
        "!pip install open3d\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\n",
        "!pip install --no-cache-dir kaolin\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install --upgrade optree\n",
        "'''"
      ],
      "metadata": {
        "id": "PtdyGSE02IiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid serach (Part 1)"
      ],
      "metadata": {
        "id": "4AD8MfjiAfUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline**:\n",
        "in this part, we explore the different hyperparameters impact on the results, we try different parameters including learning rate, Network depth, Number of sampled views, Augmentations."
      ],
      "metadata": {
        "id": "BYo4DtWZnizE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Research(LR) rangte test**"
      ],
      "metadata": {
        "id": "d9-30xkplfJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --find_lr --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/lr_finder_dog --prompt 'A 3D render of a gray dog with highlighted shoes' --seed 0 --n_augs 0 --lr_find_steps 2500"
      ],
      "metadata": {
        "id": "iCX5cY9VlmTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##dog"
      ],
      "metadata": {
        "id": "zDSJ-OSRHA5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base00 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base01 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base02 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base03 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base04 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base05 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base06 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base07 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base08 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base09 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base10 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base11 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 3 --n_views 10 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base12 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base13 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base14 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base15 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base16 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base17 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base18 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base19 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base20 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base21 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base22 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base23 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base24 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base25 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base26 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base27 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base28 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base29 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base30 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base31 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 4\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base32 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 0\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base33 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 1\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base34 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 2\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/dog.obj --output_dir results/demo_dog/base35 --prompt '3D render of a gray dog with highlighted shoes' --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 4"
      ],
      "metadata": {
        "id": "dNFg-4VbKbkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##candle"
      ],
      "metadata": {
        "id": "wDOHEfEfN43R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base13 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base17 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base21 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base25 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base29 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/candle.obj --output_dir results/demo_candle/base33 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 1 --prompt 'A 3D render of a gray candle with a highlighted hat'"
      ],
      "metadata": {
        "id": "wCtvpSHWNu9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##horse"
      ],
      "metadata": {
        "id": "gUPQnbWPN8Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base13 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 3 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base17 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 6 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base21 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 6 --n_views 10 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base25 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 3 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base29 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 6 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'\n",
        "!python ./AML-Affordance-detection/main.py --obj_path ./AML-Affordance-detection/data/horse.obj --output_dir results/demo_horse/base33 --seed 0 --classes shoes --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.000002 --depth 10 --n_views 10 --n_augs 1 --prompt 'A 3D render of a gray horse with a highlighted shoes'"
      ],
      "metadata": {
        "id": "i-1qSQf1N_AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##save the result"
      ],
      "metadata": {
        "id": "PQCvg_haQQ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip ./results\n",
        "files.download(\"./results.zip\")"
      ],
      "metadata": {
        "id": "xaEWmEsQX3Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runing on the voxel version (Part 2 and Part 3)"
      ],
      "metadata": {
        "id": "ru0qwzROlrWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we utilize the kaolin API to create voxel mesh to explore 3D Highlighter on different data and using different data augmentation strategies.Different num_object represents different object (222 kniffe,display, 99 earphone, 556 chair,1280 storage furnitureï¼Œ287 faucet, 1430 table)"
      ],
      "metadata": {
        "id": "JlwC7dmOlB2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is for test\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 100 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3"
      ],
      "metadata": {
        "id": "-Kxh6KVh9uIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update hyperparameters\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 1 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 2 --learning_rate 0.0001 --depth 5 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 3 --learning_rate 0.0001 --depth 6 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 5 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 5"
      ],
      "metadata": {
        "id": "Dd7fUip9dwnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 1 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 2 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 3 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 5\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 5 --n_views 5\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 5\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 4\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 5 --n_views 4\n",
        "!python ./AML-Affordance-detection/main.py --num_object 2 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IwcgY2kblx9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 1 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 2 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 3 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 5 --n_views 5\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 5 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 5\n",
        "!python ./AML-Affordance-detection/main.py --num_object 112 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3"
      ],
      "metadata": {
        "id": "heufzsBZl0N_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 99 --seed 10 --n_iter 1500 --voxel True --n_augs 1 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 99 --seed 10 --n_iter 1500 --voxel True --n_augs 4 --learning_rate 0.0001 --depth 4 --n_views 3"
      ],
      "metadata": {
        "id": "OGGmbEpQyZOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r voxel_results.zip ./voxel_results\n",
        "files.download(\"./voxel_results.zip\")"
      ],
      "metadata": {
        "id": "0monxCxzDY4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./voxel_results ./drive/MyDrive/results"
      ],
      "metadata": {
        "id": "Vu1PR1y8shEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running on the approximate mesh (Trashed)\n"
      ],
      "metadata": {
        "id": "B5o2NI-yvL7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we utilize the kaolin API to create voxel mesh to explore 3D Highlighter on different data and using different data augmentation strategies, but we find the approximate mesh doesn't have a good performance, so we discard this method."
      ],
      "metadata": {
        "id": "RL7ttIiTiNxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the results obviously are not good\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 1 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ODmj6xnHf0il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 1 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 2 --learning_rate 0.0001 --depth 4 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 3 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 380 --n_iter 1500 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3"
      ],
      "metadata": {
        "id": "EkMw_mJ5vVnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 1 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 2 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 3 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 0 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 6 --n_views 3"
      ],
      "metadata": {
        "id": "CzYL3kkAfyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 1 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 2 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 3 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 6\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 3 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.0001 --depth 6 --n_views 3\n",
        "!python ./AML-Affordance-detection/main.py --num_object 1 --seed 2057 --n_iter 1000 --appro_mesh True --n_augs 4 --learning_rate 0.001 --depth 6 --n_views 3"
      ],
      "metadata": {
        "id": "rKGM3jXVfyny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r appro_results.zip ./appro_results\n",
        "files.download(\"./appro_results.zip\")\n",
        "!cp -r ./appro_results ./drive/MyDrive/results"
      ],
      "metadata": {
        "id": "INSQgaQYXXYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Pus0peAOEphU"
      ],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}